{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéôÔ∏è Karakalpak VITS TTS Model Training on Google Colab\n",
    "\n",
    "This notebook provides a complete pipeline for fine-tuning a VITS (Variational Inference Text-to-Speech) model for Karakalpak language using the MMS (Massively Multilingual Speech) architecture.\n",
    "\n",
    "## üìã Overview\n",
    "- **Model**: MMS-TTS (VITS architecture)\n",
    "- **Language**: Karakalpak (kaa)\n",
    "- **Dataset**: HuggingFace dataset `nickoo004/karakalpak-tts-speaker1`\n",
    "- **Training Time**: ~20-30 minutes on Colab GPU\n",
    "- **‚úÖ Works with Private Repositories** - No authentication needed!\n",
    "\n",
    "## üöÄ Steps:\n",
    "1. Environment Setup & Dependencies\n",
    "2. Download Repository (ZIP method - works with private repos!)\n",
    "3. Dataset Loading from HuggingFace\n",
    "4. Model Preparation\n",
    "5. Training Configuration\n",
    "6. Model Training\n",
    "7. Inference & Testing\n",
    "8. Model Saving & Upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Environment Setup & GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"üîç GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üìä GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è WARNING: No GPU detected! Training will be very slow.\")\n",
    "    print(\"Please enable GPU in Runtime > Change runtime type > Hardware accelerator > GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Install Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Install core dependencies\n",
    "pip install -q transformers>=4.35.1 datasets[audio]>=2.14.7 accelerate>=0.24.1\n",
    "pip install -q matplotlib wandb tensorboard Cython\n",
    "pip install -q scipy librosa soundfile\n",
    "\n",
    "echo \"‚úÖ Dependencies installed successfully!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Download Repository (Works with Private Repos!)\n",
    "\n",
    "**‚úÖ No Authentication Required** - Downloads the repository as a ZIP file directly from GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import shutil\n",
    "\n",
    "repo_name = \"my-vits-finetuner-karakalpak\"\n",
    "\n",
    "# IMPORTANT: Update this URL if your main branch is named differently\n",
    "# For 'main' branch: /archive/refs/heads/main.zip\n",
    "# For 'master' branch: /archive/refs/heads/master.zip\n",
    "zip_url = \"https://github.com/NursultanMRX/my-vits-finetuner-karakalpak/archive/refs/heads/main.zip\"\n",
    "\n",
    "if not os.path.exists(repo_name):\n",
    "    print(f\"üì• Downloading repository as ZIP (no authentication needed)...\")\n",
    "    zip_path = \"repo.zip\"\n",
    "    \n",
    "    try:\n",
    "        # Download the zip file\n",
    "        urllib.request.urlretrieve(zip_url, zip_path)\n",
    "        print(\"‚úÖ Downloaded successfully!\")\n",
    "        \n",
    "        # Extract the zip file\n",
    "        print(\"üì¶ Extracting files...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(\".\")\n",
    "        \n",
    "        # The extracted folder has '-main' or '-master' suffix\n",
    "        extracted_name = None\n",
    "        for suffix in ['-main', '-master']:\n",
    "            possible_name = f\"{repo_name}{suffix}\"\n",
    "            if os.path.exists(possible_name):\n",
    "                extracted_name = possible_name\n",
    "                break\n",
    "        \n",
    "        if extracted_name:\n",
    "            shutil.move(extracted_name, repo_name)\n",
    "            print(f\"‚úÖ Renamed '{extracted_name}' to '{repo_name}'\")\n",
    "        else:\n",
    "            raise Exception(f\"Could not find extracted directory\")\n",
    "        \n",
    "        # Clean up\n",
    "        os.remove(zip_path)\n",
    "        print(\"‚úÖ Repository ready!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        print(\"\\n‚ö†Ô∏è Please check:\")\n",
    "        print(\"1. Repository exists and is accessible\")\n",
    "        print(\"2. Branch name is correct (main or master)\")\n",
    "        raise\n",
    "else:\n",
    "    print(\"‚úÖ Repository already exists!\")\n",
    "\n",
    "# Change to repository directory\n",
    "if os.path.exists(repo_name):\n",
    "    os.chdir(repo_name)\n",
    "    print(f\"üìÇ Current directory: {os.getcwd()}\")\n",
    "    \n",
    "    files = os.listdir('.')\n",
    "    print(f\"\\nüìã Repository contains {len(files)} items\")\n",
    "    key_files = [f for f in ['run_vits_finetuning.py', 'monotonic_align', 'utils'] if f in files]\n",
    "    print(f\"   Key files present: {', '.join(key_files)}\")\n",
    "else:\n",
    "    raise Exception(f\"‚ùå Directory '{repo_name}' does not exist!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£.1 Build Monotonic Align Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Build the Cython monotonic alignment module (CRITICAL for fast training)\n",
    "echo \"üî® Building monotonic alignment module...\"\n",
    "\n",
    "if [ ! -d \"monotonic_align\" ]; then\n",
    "    echo \"‚ùå Error: monotonic_align directory not found!\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "cd monotonic_align\n",
    "mkdir -p monotonic_align\n",
    "python setup.py build_ext --inplace\n",
    "\n",
    "if [ $? -eq 0 ]; then\n",
    "    echo \"‚úÖ Monotonic align built successfully!\"\n",
    "else\n",
    "    echo \"‚ùå Failed to build!\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ HuggingFace Authentication (Optional)\n",
    "\n",
    "**Only needed if you want to:**\n",
    "- Push your trained model to HuggingFace Hub\n",
    "- Access private datasets\n",
    "\n",
    "Get your token from: https://huggingface.co/settings/tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "# Login to HuggingFace (optional - skip if you don't want to push to hub)\n",
    "try:\n",
    "    notebook_login()\n",
    "    print(\"‚úÖ Successfully logged in to HuggingFace!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Login skipped: {e}\")\n",
    "    print(\"You can continue training, but won't be able to push to Hub\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Load Dataset from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "import os\n",
    "\n",
    "# Load the Karakalpak TTS dataset\n",
    "dataset_name = \"nickoo004/karakalpak-tts-speaker1\"\n",
    "\n",
    "print(f\"üìä Loading dataset: {dataset_name}\")\n",
    "\n",
    "try:\n",
    "    # Try default loading\n",
    "    dataset = load_dataset(dataset_name)\n",
    "    print(\"‚úÖ Dataset loaded successfully!\")\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(f\"‚ö†Ô∏è Default loading failed: {e}\")\n",
    "    print(\"\\nüîÑ Trying alternative methods...\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Try with trust_remote_code\n",
    "        dataset = load_dataset(dataset_name, trust_remote_code=True)\n",
    "        print(\"‚úÖ Loaded with trust_remote_code=True!\")\n",
    "    except:\n",
    "        try:\n",
    "            # Try explicit split\n",
    "            dataset = load_dataset(dataset_name, split='train')\n",
    "            if not isinstance(dataset, DatasetDict):\n",
    "                dataset = DatasetDict({'train': dataset})\n",
    "            print(\"‚úÖ Loaded with explicit split!\")\n",
    "        except Exception as e2:\n",
    "            print(f\"‚ùå All methods failed: {e2}\")\n",
    "            print(\"\\n‚ö†Ô∏è SOLUTION: Fix dataset metadata on HuggingFace\")\n",
    "            print(\"Your metadata.csv needs a 'file_name' column\")\n",
    "            print(\"See instructions in the next cell below\")\n",
    "            raise\n",
    "\n",
    "print(f\"\\nüìà Dataset structure:\")\n",
    "print(dataset)\n",
    "\n",
    "# Show sample\n",
    "if 'train' in dataset:\n",
    "    sample = dataset['train'][0]\n",
    "    print(\"\\nüîç Sample from dataset:\")\n",
    "    print(f\"  Keys: {list(sample.keys())}\")\n",
    "    \n",
    "    # Find columns\n",
    "    text_col = sample.get('text', sample.get('sentence', 'N/A'))\n",
    "    print(f\"  - Text: {text_col}\")\n",
    "    \n",
    "    audio_col = None\n",
    "    for col in ['audio', 'audio_file', 'file', 'path', 'file_name']:\n",
    "        if col in sample:\n",
    "            audio_col = col\n",
    "            print(f\"  - Audio column: '{col}'\")\n",
    "            break\n",
    "    \n",
    "    speaker_col = None\n",
    "    for col in ['speaker_name', 'speaker', 'speaker_id']:\n",
    "        if col in sample:\n",
    "            speaker_col = col\n",
    "            print(f\"  - Speaker column: '{col}' = {sample[col]}\")\n",
    "            break\n",
    "    \n",
    "    print(f\"\\nüìä Total samples: {len(dataset['train'])}\")\n",
    "    \n",
    "    if audio_col:\n",
    "        print(f\"\\nüí° Use audio_column_name='{audio_col}' in training config\")\n",
    "    if speaker_col:\n",
    "        print(f\"üí° Use speaker_id_column_name='{speaker_col}' in training config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù If Dataset Loading Fails - How to Fix\n",
    "\n",
    "**The metadata file on HuggingFace needs proper format:**\n",
    "\n",
    "**Required metadata.csv format:**\n",
    "```csv\n",
    "file_name,text,speaker_name\n",
    "audio_001.wav,\"S√°lem, qalaysƒ±z?\",Speaker_1\n",
    "audio_002.wav,\"M√∫g√°lim j√°qsƒ±.\",Speaker_1\n",
    "```\n",
    "\n",
    "**Or metadata.jsonl format:**\n",
    "```json\n",
    "{\"file_name\": \"audio_001.wav\", \"text\": \"S√°lem, qalaysƒ±z?\", \"speaker_name\": \"Speaker_1\"}\n",
    "{\"file_name\": \"audio_002.wav\", \"text\": \"M√∫g√°lim j√°qsƒ±.\", \"speaker_name\": \"Speaker_1\"}\n",
    "```\n",
    "\n",
    "**To fix:**\n",
    "1. Go to: https://huggingface.co/datasets/nickoo004/karakalpak-tts-speaker1\n",
    "2. Edit your metadata file\n",
    "3. Add `file_name` column\n",
    "4. Upload and refresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîß Alternative: Manual Dataset Upload\n",
    "\n",
    "**Uncomment and run this cell if automatic loading fails:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL DATASET LOADING (uncomment if needed)\n",
    "\n",
    "# from datasets import Dataset, Audio, DatasetDict\n",
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # Upload your dataset folder to Colab, then update these paths:\n",
    "# dataset_dir = \"/content/karakalpak_dataset\"  # Your dataset directory\n",
    "# metadata_file = f\"{dataset_dir}/metadata.csv\"\n",
    "\n",
    "# # Load metadata\n",
    "# df = pd.read_csv(metadata_file)\n",
    "\n",
    "# # Add full audio paths\n",
    "# df['audio_file'] = df['file_name'].apply(lambda x: os.path.join(dataset_dir, 'audio', x))\n",
    "\n",
    "# # Create dataset\n",
    "# dataset = Dataset.from_pandas(df)\n",
    "# dataset = dataset.cast_column('audio_file', Audio(sampling_rate=16000))\n",
    "# dataset = DatasetDict({'train': dataset})\n",
    "\n",
    "# print(\"‚úÖ Manual dataset loaded!\")\n",
    "# print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Prepare Base Model with Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import list_repo_files\n",
    "\n",
    "model_name_or_path = \"facebook/mms-tts-kaa\"\n",
    "local_model_dir = \"./mms-tts-kaa-with-discriminator\"\n",
    "\n",
    "# Check if pre-converted model exists\n",
    "try:\n",
    "    test_model = \"nickoo004/mms-tts-kaa-with-discriminator\"\n",
    "    files = list_repo_files(test_model)\n",
    "    if 'discriminator.pth' in files or 'pytorch_model.bin' in files:\n",
    "        print(f\"‚úÖ Found existing model: {test_model}\")\n",
    "        model_name_or_path = test_model\n",
    "    else:\n",
    "        raise Exception(\"Need to convert\")\n",
    "except:\n",
    "    print(f\"\\nüìù Converting base MMS model...\")\n",
    "    print(f\"   Base: {model_name_or_path}\")\n",
    "    \n",
    "    !python convert_original_discriminator_checkpoint.py \\\n",
    "        --language_code kaa \\\n",
    "        --pytorch_dump_folder_path {local_model_dir}\n",
    "    \n",
    "    model_name_or_path = local_model_dir\n",
    "    print(f\"\\n‚úÖ Model converted: {model_name_or_path}\")\n",
    "\n",
    "print(f\"\\nüéØ Model ready: {model_name_or_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Configure Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "training_config = {\n",
    "    # Model and Dataset\n",
    "    \"model_name_or_path\": model_name_or_path,\n",
    "    \"dataset_name\": \"nickoo004/karakalpak-tts-speaker1\",\n",
    "    \n",
    "    # Output\n",
    "    \"output_dir\": \"./mms-tts-kaa-finetuned-speaker1\",\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \n",
    "    # HuggingFace Hub (optional)\n",
    "    \"push_to_hub\": False,\n",
    "    \"hub_model_id\": \"your-username/mms-tts-kaa-finetuned-speaker1\",\n",
    "    \n",
    "    # Dataset columns (adjust based on your dataset)\n",
    "    \"audio_column_name\": \"audio_file\",\n",
    "    \"text_column_name\": \"text\",\n",
    "    \"speaker_id_column_name\": \"speaker_name\",\n",
    "    \"filter_on_speaker_id\": \"Speaker_1\",\n",
    "    \"override_speaker_embeddings\": True,\n",
    "    \n",
    "    # Audio filtering\n",
    "    \"max_duration_in_seconds\": 20.0,\n",
    "    \"min_duration_in_seconds\": 1.0,\n",
    "    \n",
    "    # Training hyperparameters\n",
    "    \"num_train_epochs\": 150,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"warmup_ratio\": 0.01,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"gradient_checkpointing\": False,\n",
    "    \"group_by_length\": False,\n",
    "    \n",
    "    # Training flags\n",
    "    \"do_train\": True,\n",
    "    \"do_eval\": False,\n",
    "    \n",
    "    # Loss weights\n",
    "    \"weight_disc\": 3.0,\n",
    "    \"weight_fmaps\": 1.0,\n",
    "    \"weight_gen\": 1.0,\n",
    "    \"weight_kl\": 1.5,\n",
    "    \"weight_duration\": 1.0,\n",
    "    \"weight_mel\": 35.0,\n",
    "    \n",
    "    # Optimization\n",
    "    \"fp16\": True,\n",
    "    \"seed\": 42,\n",
    "    \n",
    "    # Logging\n",
    "    \"logging_steps\": 10,\n",
    "    \"save_steps\": 500,\n",
    "    \"save_total_limit\": 2,\n",
    "}\n",
    "\n",
    "config_path = \"./training_config_colab.json\"\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(training_config, f, indent=4)\n",
    "\n",
    "print(\"‚úÖ Training configuration created!\")\n",
    "print(\"\\nüìã Key settings:\")\n",
    "print(f\"  - Model: {training_config['model_name_or_path']}\")\n",
    "print(f\"  - Dataset: {training_config['dataset_name']}\")\n",
    "print(f\"  - Epochs: {training_config['num_train_epochs']}\")\n",
    "print(f\"  - Batch size: {training_config['per_device_train_batch_size']}\")\n",
    "print(f\"  - Learning rate: {training_config['learning_rate']}\")\n",
    "print(f\"  - Output: {training_config['output_dir']}\")\n",
    "print(f\"\\nüìÑ Config saved to: {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Start Training! üöÄ\n",
    "\n",
    "**This will take ~20-30 minutes on a T4 GPU**\n",
    "\n",
    "If you get OOM errors, reduce `per_device_train_batch_size` to 2 or 1 in the config above and re-run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training\n",
    "!accelerate launch run_vits_finetuning.py {config_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Test Your Trained Model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import VitsModel, AutoTokenizer\n",
    "import torch\n",
    "import scipy.io.wavfile\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "model_path = training_config['output_dir']\n",
    "\n",
    "print(f\"üì• Loading model from: {model_path}\")\n",
    "model = VitsModel.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"‚úÖ Model loaded on {device}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with Karakalpak text\n",
    "test_texts = [\n",
    "    \"S√°lem, qalaysƒ±z?\",\n",
    "    \"M√∫g√°lim j√°qsƒ±.\",\n",
    "    \"Men oqƒ±p atƒ±rman.\",\n",
    "]\n",
    "\n",
    "print(\"üé§ Generating speech...\\n\")\n",
    "\n",
    "for i, text in enumerate(test_texts, 1):\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Sample {i}: {text}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    waveform = outputs.waveform[0].cpu().numpy()\n",
    "    \n",
    "    output_file = f\"output_{i}.wav\"\n",
    "    scipy.io.wavfile.write(\n",
    "        output_file,\n",
    "        rate=model.config.sampling_rate,\n",
    "        data=waveform\n",
    "    )\n",
    "    \n",
    "    print(f\"üíæ Saved: {output_file}\")\n",
    "    display(Audio(waveform, rate=model.config.sampling_rate))\n",
    "    print()\n",
    "\n",
    "print(\"‚úÖ All samples generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîü Custom Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your own text here!\n",
    "custom_text = \"S√°lem, bul men!\"\n",
    "\n",
    "print(f\"üìù Generating: {custom_text}\\n\")\n",
    "\n",
    "inputs = tokenizer(custom_text, return_tensors=\"pt\").to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "waveform = outputs.waveform[0].cpu().numpy()\n",
    "output_file = \"custom_output.wav\"\n",
    "scipy.io.wavfile.write(output_file, rate=model.config.sampling_rate, data=waveform)\n",
    "\n",
    "print(f\"‚úÖ Saved: {output_file}\\n\")\n",
    "display(Audio(waveform, rate=model.config.sampling_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Push to HuggingFace Hub (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "push_to_hub = False  # Set to True to push\n",
    "\n",
    "if push_to_hub:\n",
    "    hub_model_id = training_config['hub_model_id']\n",
    "    \n",
    "    if \"your-username\" not in hub_model_id:\n",
    "        print(f\"üì§ Pushing to: {hub_model_id}\")\n",
    "        model.push_to_hub(hub_model_id)\n",
    "        tokenizer.push_to_hub(hub_model_id)\n",
    "        print(f\"\\n‚úÖ Pushed to: https://huggingface.co/{hub_model_id}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Update hub_model_id first!\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Skipping push (set push_to_hub=True to enable)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£2Ô∏è‚É£ Download Model Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "output_dir = training_config['output_dir']\n",
    "zip_filename = \"mms-tts-kaa-finetuned\"\n",
    "\n",
    "print(f\"üì¶ Creating ZIP archive...\")\n",
    "shutil.make_archive(zip_filename, 'zip', output_dir)\n",
    "\n",
    "print(f\"\\n‚úÖ Archived: {zip_filename}.zip\")\n",
    "print(f\"üì• Download from Files panel on the left\")\n",
    "print(f\"   Size: {os.path.getsize(f'{zip_filename}.zip') / (1024*1024):.2f} MB\")\n",
    "\n",
    "print(f\"\\nüìÇ Model files:\")\n",
    "for file in os.listdir(output_dir):\n",
    "    file_path = os.path.join(output_dir, file)\n",
    "    if os.path.isfile(file_path):\n",
    "        size = os.path.getsize(file_path) / (1024*1024)\n",
    "        print(f\"  - {file}: {size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Congratulations!\n",
    "\n",
    "### You've successfully trained a Karakalpak TTS model!\n",
    "\n",
    "**What you accomplished:**\n",
    "- ‚úÖ Set up the environment\n",
    "- ‚úÖ Downloaded the code (from private repo!)\n",
    "- ‚úÖ Loaded the dataset\n",
    "- ‚úÖ Fine-tuned the model\n",
    "- ‚úÖ Generated speech samples\n",
    "- ‚úÖ Saved the model\n",
    "\n",
    "**Next steps:**\n",
    "1. Experiment with more epochs (200-300)\n",
    "2. Try different hyperparameters\n",
    "3. Add more training data\n",
    "4. Deploy your model\n",
    "5. Share on HuggingFace Hub\n",
    "\n",
    "**Resources:**\n",
    "- [VITS Paper](https://arxiv.org/abs/2106.06103)\n",
    "- [MMS Paper](https://arxiv.org/abs/2305.13516)\n",
    "- [HF VITS Docs](https://huggingface.co/docs/transformers/model_doc/vits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Troubleshooting\n",
    "\n",
    "**1. Out of Memory (OOM):**\n",
    "- Reduce batch size to 2 or 1\n",
    "- Enable gradient_checkpointing\n",
    "- Ensure GPU is enabled\n",
    "\n",
    "**2. Dataset loading fails:**\n",
    "- Fix metadata.csv to include `file_name` column\n",
    "- Or use manual upload method\n",
    "- Check dataset exists on HuggingFace\n",
    "\n",
    "**3. Training is slow:**\n",
    "- Confirm GPU is enabled\n",
    "- Check fp16=True\n",
    "- Verify monotonic_align built correctly\n",
    "\n",
    "**4. Repository download fails:**\n",
    "- Check internet connection\n",
    "- Verify branch name (main vs master)\n",
    "- Check repository exists and is accessible\n",
    "\n",
    "**5. Build errors:**\n",
    "- Ensure Cython is installed\n",
    "- Check numpy is available\n",
    "- Try restarting runtime"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
