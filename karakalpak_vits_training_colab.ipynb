{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# üéôÔ∏è Karakalpak VITS TTS Model Training on Google Colab\n\nThis notebook provides a complete pipeline for fine-tuning a VITS (Variational Inference Text-to-Speech) model for Karakalpak language using the MMS (Massively Multilingual Speech) architecture.\n\n## üìã Overview\n- **Model**: MMS-TTS (VITS architecture)\n- **Language**: Karakalpak (kaa)\n- **Dataset**: HuggingFace dataset `nickoo004/karakalpak-tts-speaker1`\n- **Training Time**: ~20-30 minutes on Colab GPU\n- **‚úÖ Works with Private Repositories** - No authentication needed!\n\n## ‚ö†Ô∏è IMPORTANT: Run Cells in Order!\n\n**This notebook MUST be run from top to bottom, cell by cell!**\n\nDo NOT skip cells or run them out of order, or you'll get errors like:\n- \"File not found\"\n- \"Variable not defined\"\n- \"Directory doesn't exist\"\n\n**Recommended**: Use `Runtime > Run all` to run everything in order automatically.\n\n## üöÄ Steps:\n1. Environment Setup & Dependencies\n2. Download Repository (ZIP method - works with private repos!)\n3. Dataset Loading from HuggingFace\n4. Model Preparation\n5. Training Configuration\n6. Model Training\n7. Inference & Testing\n8. Model Saving & Upload"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Environment Setup & GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"üîç GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"üìä GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è WARNING: No GPU detected! Training will be very slow.\")\n",
    "    print(\"Please enable GPU in Runtime > Change runtime type > Hardware accelerator > GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Install Required Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Install core dependencies\n",
    "pip install -q transformers>=4.35.1 datasets[audio]>=2.14.7 accelerate>=0.24.1\n",
    "pip install -q matplotlib wandb tensorboard Cython\n",
    "pip install -q scipy librosa soundfile\n",
    "\n",
    "echo \"‚úÖ Dependencies installed successfully!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Download Repository (Works with Private Repos!)\n",
    "\n",
    "**‚úÖ No Authentication Required** - Downloads the repository as a ZIP file directly from GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import shutil\n",
    "\n",
    "repo_name = \"my-vits-finetuner-karakalpak\"\n",
    "\n",
    "# IMPORTANT: Update this URL if your main branch is named differently\n",
    "# For 'main' branch: /archive/refs/heads/main.zip\n",
    "# For 'master' branch: /archive/refs/heads/master.zip\n",
    "zip_url = \"https://github.com/NursultanMRX/my-vits-finetuner-karakalpak/archive/refs/heads/main.zip\"\n",
    "\n",
    "if not os.path.exists(repo_name):\n",
    "    print(f\"üì• Downloading repository as ZIP (no authentication needed)...\")\n",
    "    zip_path = \"repo.zip\"\n",
    "    \n",
    "    try:\n",
    "        # Download the zip file\n",
    "        urllib.request.urlretrieve(zip_url, zip_path)\n",
    "        print(\"‚úÖ Downloaded successfully!\")\n",
    "        \n",
    "        # Extract the zip file\n",
    "        print(\"üì¶ Extracting files...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(\".\")\n",
    "        \n",
    "        # The extracted folder has '-main' or '-master' suffix\n",
    "        extracted_name = None\n",
    "        for suffix in ['-main', '-master']:\n",
    "            possible_name = f\"{repo_name}{suffix}\"\n",
    "            if os.path.exists(possible_name):\n",
    "                extracted_name = possible_name\n",
    "                break\n",
    "        \n",
    "        if extracted_name:\n",
    "            shutil.move(extracted_name, repo_name)\n",
    "            print(f\"‚úÖ Renamed '{extracted_name}' to '{repo_name}'\")\n",
    "        else:\n",
    "            raise Exception(f\"Could not find extracted directory\")\n",
    "        \n",
    "        # Clean up\n",
    "        os.remove(zip_path)\n",
    "        print(\"‚úÖ Repository ready!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        print(\"\\n‚ö†Ô∏è Please check:\")\n",
    "        print(\"1. Repository exists and is accessible\")\n",
    "        print(\"2. Branch name is correct (main or master)\")\n",
    "        raise\n",
    "else:\n",
    "    print(\"‚úÖ Repository already exists!\")\n",
    "\n",
    "# Change to repository directory\n",
    "if os.path.exists(repo_name):\n",
    "    os.chdir(repo_name)\n",
    "    print(f\"üìÇ Current directory: {os.getcwd()}\")\n",
    "    \n",
    "    files = os.listdir('.')\n",
    "    print(f\"\\nüìã Repository contains {len(files)} items\")\n",
    "    key_files = [f for f in ['run_vits_finetuning.py', 'monotonic_align', 'utils'] if f in files]\n",
    "    print(f\"   Key files present: {', '.join(key_files)}\")\n",
    "else:\n",
    "    raise Exception(f\"‚ùå Directory '{repo_name}' does not exist!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%bash\n# ========================================\n# 3Ô∏è‚É£.1 Build Monotonic Align Module\n# ========================================\n# Build the Cython monotonic alignment module (CRITICAL for fast training)\necho \"üî® Building monotonic alignment module...\"\n\nif [ ! -d \"monotonic_align\" ]; then\n    echo \"‚ùå Error: monotonic_align directory not found!\"\n    exit 1\nfi\n\ncd monotonic_align\nmkdir -p monotonic_align\npython setup.py build_ext --inplace\n\nif [ $? -eq 0 ]; then\n    echo \"‚úÖ Monotonic align built successfully!\"\nelse\n    echo \"‚ùå Failed to build!\"\n    exit 1\nfi\n\ncd .."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ HuggingFace Authentication (Optional)\n",
    "\n",
    "**Only needed if you want to:**\n",
    "- Push your trained model to HuggingFace Hub\n",
    "- Access private datasets\n",
    "\n",
    "Get your token from: https://huggingface.co/settings/tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "# Login to HuggingFace (optional - skip if you don't want to push to hub)\n",
    "try:\n",
    "    notebook_login()\n",
    "    print(\"‚úÖ Successfully logged in to HuggingFace!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Login skipped: {e}\")\n",
    "    print(\"You can continue training, but won't be able to push to Hub\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Load Dataset from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from datasets import load_dataset, DatasetDict\nimport os\n\n# Load the Karakalpak TTS dataset\ndataset_name = \"nickoo004/karakalpak-tts-speaker1\"\n\nprint(f\"üìä Loading dataset: {dataset_name}\")\n\ntry:\n    # Try default loading\n    dataset = load_dataset(dataset_name)\n    print(\"‚úÖ Dataset loaded successfully!\")\n    \nexcept ValueError as e:\n    error_msg = str(e)\n    print(f\"‚ö†Ô∏è Default loading failed: {error_msg}\")\n    \n    # Check if it's the file_name column issue\n    if \"file_name\" in error_msg or \"*_file_name\" in error_msg:\n        print(\"\\\\nüîß Detected column name issue - trying workaround...\")\n        print(\"   Loading with custom processing...\\\\n\")\n        \n        try:\n            # Load using datasets library with audiofolder\n            from datasets import load_dataset\n            \n            # Load as audio dataset (it will auto-detect the structure)\n            dataset = load_dataset(\n                \"audiofolder\",\n                data_dir=f\"hf://datasets/{dataset_name}\",\n                drop_labels=False\n            )\n            print(\"‚úÖ Loaded using audiofolder method!\")\n            \n        except Exception as e2:\n            print(f\"‚ùå Workaround failed: {e2}\")\n            print(\"\\\\n‚ö†Ô∏è PLEASE FIX THE DATASET:\")\n            print(\"Go to HuggingFace and rename 'audio_file' to 'file_name' in metadata.csv\")\n            print(\"See instructions below for exact steps.\")\n            raise\n    else:\n        # Different error - try other methods\n        print(\"\\\\nüîÑ Trying alternative methods...\\\\n\")\n        \n        try:\n            dataset = load_dataset(dataset_name, split='train')\n            if not isinstance(dataset, DatasetDict):\n                from datasets import DatasetDict\n                dataset = DatasetDict({'train': dataset})\n            print(\"‚úÖ Loaded with explicit split!\")\n        except Exception as e2:\n            print(f\"‚ùå All methods failed: {e2}\")\n            print(\"\\\\n‚ö†Ô∏è SOLUTION: Fix dataset metadata on HuggingFace\")\n            print(\"Your metadata.csv needs a 'file_name' column\")\n            print(\"See instructions in the next cell below\")\n            raise\n\nprint(f\"\\\\nüìà Dataset structure:\")\nprint(dataset)\n\n# Show sample\nif 'train' in dataset:\n    sample = dataset['train'][0]\n    print(\"\\\\nüîç Sample from dataset:\")\n    print(f\"  Keys: {list(sample.keys())}\")\n    \n    # Find columns\n    text_col = sample.get('text', sample.get('sentence', 'N/A'))\n    print(f\"  - Text: {text_col}\")\n    \n    audio_col = None\n    for col in ['audio', 'audio_file', 'file', 'path', 'file_name']:\n        if col in sample:\n            audio_col = col\n            print(f\"  - Audio column: '{col}'\")\n            break\n    \n    speaker_col = None\n    for col in ['speaker_name', 'speaker', 'speaker_id']:\n        if col in sample:\n            speaker_col = col\n            print(f\"  - Speaker column: '{col}' = {sample[col]}\")\n            break\n    \n    print(f\"\\\\nüìä Total samples: {len(dataset['train'])}\")\n    \n    if audio_col:\n        print(f\"\\\\nüí° Use audio_column_name='{audio_col}' in training config\")\n    if speaker_col:\n        print(f\"üí° Use speaker_id_column_name='{speaker_col}' in training config\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### üìù How to Fix Your Dataset on HuggingFace\n\n**Your Issue**: The metadata has `\"audio_file\"` but needs `\"file_name\"`\n\n**Quick Fix (2 minutes):**\n\n1. Go to: https://huggingface.co/datasets/nickoo004/karakalpak-tts-speaker1\n2. Click **\"Files and versions\"** tab\n3. Find and click on **metadata.csv**\n4. Click **\"Edit\"** button (pencil icon)\n5. Change the FIRST line from:\n   ```csv\n   \"audio_file\",\"text\",\"speaker_name\"\n   ```\n   To:\n   ```csv\n   \"file_name\",\"text\",\"speaker_name\"\n   ```\n6. Click **\"Commit changes to main\"**\n7. Wait 1-2 minutes for HuggingFace to process\n8. Come back and re-run the dataset loading cell above\n\n**Alternative**: If editing doesn't work, download the metadata.csv, rename the column locally, and re-upload it.\n\n**After fixing**, the automatic loading will work perfectly!"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîß Alternative: Manual Dataset Upload\n",
    "\n",
    "**Uncomment and run this cell if automatic loading fails:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUAL DATASET LOADING (uncomment if needed)\n",
    "\n",
    "# from datasets import Dataset, Audio, DatasetDict\n",
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # Upload your dataset folder to Colab, then update these paths:\n",
    "# dataset_dir = \"/content/karakalpak_dataset\"  # Your dataset directory\n",
    "# metadata_file = f\"{dataset_dir}/metadata.csv\"\n",
    "\n",
    "# # Load metadata\n",
    "# df = pd.read_csv(metadata_file)\n",
    "\n",
    "# # Add full audio paths\n",
    "# df['audio_file'] = df['file_name'].apply(lambda x: os.path.join(dataset_dir, 'audio', x))\n",
    "\n",
    "# # Create dataset\n",
    "# dataset = Dataset.from_pandas(df)\n",
    "# dataset = dataset.cast_column('audio_file', Audio(sampling_rate=16000))\n",
    "# dataset = DatasetDict({'train': dataset})\n",
    "\n",
    "# print(\"‚úÖ Manual dataset loaded!\")\n",
    "# print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Prepare Base Model with Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import list_repo_files\n",
    "\n",
    "model_name_or_path = \"facebook/mms-tts-kaa\"\n",
    "local_model_dir = \"./mms-tts-kaa-with-discriminator\"\n",
    "\n",
    "# Check if pre-converted model exists\n",
    "try:\n",
    "    test_model = \"nickoo004/mms-tts-kaa-with-discriminator\"\n",
    "    files = list_repo_files(test_model)\n",
    "    if 'discriminator.pth' in files or 'pytorch_model.bin' in files:\n",
    "        print(f\"‚úÖ Found existing model: {test_model}\")\n",
    "        model_name_or_path = test_model\n",
    "    else:\n",
    "        raise Exception(\"Need to convert\")\n",
    "except:\n",
    "    print(f\"\\nüìù Converting base MMS model...\")\n",
    "    print(f\"   Base: {model_name_or_path}\")\n",
    "    \n",
    "    !python convert_original_discriminator_checkpoint.py \\\n",
    "        --language_code kaa \\\n",
    "        --pytorch_dump_folder_path {local_model_dir}\n",
    "    \n",
    "    model_name_or_path = local_model_dir\n",
    "    print(f\"\\n‚úÖ Model converted: {model_name_or_path}\")\n",
    "\n",
    "print(f\"\\nüéØ Model ready: {model_name_or_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Configure Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json\nimport os\n\n# Make sure we're in the repository directory\nrepo_dir = \"/content/my-vits-finetuner-karakalpak\"\nif os.path.exists(repo_dir):\n    os.chdir(repo_dir)\n    print(f\"üìÇ Working in: {os.getcwd()}\")\nelse:\n    print(\"‚ö†Ô∏è Warning: Repository directory not found. Run Section 3 cells first!\")\n\ntraining_config = {\n    # Model and Dataset\n    \"model_name_or_path\": model_name_or_path,\n    \"dataset_name\": \"nickoo004/karakalpak-tts-speaker1\",\n    \n    # Output\n    \"output_dir\": \"./mms-tts-kaa-finetuned-speaker1\",\n    \"overwrite_output_dir\": True,\n    \n    # HuggingFace Hub (optional)\n    \"push_to_hub\": False,\n    \"hub_model_id\": \"your-username/mms-tts-kaa-finetuned-speaker1\",\n    \n    # Dataset columns (IMPORTANT: adjust based on what the dataset loading showed)\n    \"audio_column_name\": \"audio\",  # Change this if dataset loading showed different name\n    \"text_column_name\": \"text\",\n    \"speaker_id_column_name\": \"speaker_name\",\n    \"filter_on_speaker_id\": \"Speaker_1\",\n    \"override_speaker_embeddings\": True,\n    \n    # Audio filtering\n    \"max_duration_in_seconds\": 20.0,\n    \"min_duration_in_seconds\": 1.0,\n    \n    # Training hyperparameters\n    \"num_train_epochs\": 150,\n    \"per_device_train_batch_size\": 4,\n    \"learning_rate\": 2e-5,\n    \"warmup_ratio\": 0.01,\n    \"gradient_accumulation_steps\": 1,\n    \"gradient_checkpointing\": False,\n    \"group_by_length\": False,\n    \n    # Training flags\n    \"do_train\": True,\n    \"do_eval\": False,\n    \n    # Loss weights\n    \"weight_disc\": 3.0,\n    \"weight_fmaps\": 1.0,\n    \"weight_gen\": 1.0,\n    \"weight_kl\": 1.5,\n    \"weight_duration\": 1.0,\n    \"weight_mel\": 35.0,\n    \n    # Optimization\n    \"fp16\": True,\n    \"seed\": 42,\n    \n    # Logging\n    \"logging_steps\": 10,\n    \"save_steps\": 500,\n    \"save_total_limit\": 2,\n}\n\nconfig_path = \"./training_config_colab.json\"\nwith open(config_path, 'w') as f:\n    json.dump(training_config, f, indent=4)\n\nprint(\"‚úÖ Training configuration created!\")\nprint(\"\\\\nüìã Key settings:\")\nprint(f\"  - Model: {training_config['model_name_or_path']}\")\nprint(f\"  - Dataset: {training_config['dataset_name']}\")\nprint(f\"  - Audio column: {training_config['audio_column_name']}\")\nprint(f\"  - Epochs: {training_config['num_train_epochs']}\")\nprint(f\"  - Batch size: {training_config['per_device_train_batch_size']}\")\nprint(f\"  - Learning rate: {training_config['learning_rate']}\")\nprint(f\"  - Output: {training_config['output_dir']}\")\nprint(f\"\\\\nüìÑ Config saved to: {config_path}\")\nprint(f\"\\\\n‚ö†Ô∏è IMPORTANT: If dataset loading showed different audio column name,\")\nprint(f\"   update 'audio_column_name' above and re-run this cell!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Start Training! üöÄ\n",
    "\n",
    "**This will take ~20-30 minutes on a T4 GPU**\n",
    "\n",
    "If you get OOM errors, reduce `per_device_train_batch_size` to 2 or 1 in the config above and re-run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\n\n# IMPORTANT: Verify we're in the correct directory\nrepo_dir = \"/content/my-vits-finetuner-karakalpak\"\n\nif not os.path.exists(repo_dir):\n    print(\"‚ùå ERROR: Repository directory not found!\")\n    print(f\"   Looking for: {repo_dir}\")\n    print(\"\\\\n‚ö†Ô∏è Please run the repository download cells (Section 3) first!\")\n    raise Exception(\"Repository not downloaded\")\n\n# Change to repository directory\nos.chdir(repo_dir)\nprint(f\"üìÇ Current directory: {os.getcwd()}\")\n\n# Verify the training script exists\ntraining_script = \"run_vits_finetuning.py\"\nif not os.path.exists(training_script):\n    print(f\"‚ùå ERROR: Training script not found!\")\n    print(f\"   Looking for: {training_script}\")\n    print(f\"   In directory: {os.getcwd()}\")\n    print(\"\\\\nüìã Files in current directory:\")\n    print(os.listdir('.'))\n    raise Exception(\"Training script not found\")\n\nprint(f\"‚úÖ Found training script: {training_script}\")\nprint(f\"‚úÖ Config file: {config_path}\")\nprint(\"\\\\nüöÄ Starting training...\\\\n\")\n\n# Run training using accelerate\n!accelerate launch run_vits_finetuning.py {config_path}"
  },
  {
   "cell_type": "markdown",
   "source": "### üîë IMPORTANT: Set Up HuggingFace Token for Private Dataset\n\n**If your dataset is PRIVATE**, you must set up your HuggingFace token in Colab Secrets:\n\n1. Click the **üîë key icon** in the left sidebar (Secrets)\n2. Click **\"+ Add new secret\"**\n3. Name: **`HF_TOKEN`**\n4. Value: Your HuggingFace token from https://huggingface.co/settings/tokens\n5. Enable **\"Notebook access\"** toggle\n\n**If your dataset is PUBLIC**, you can skip this step.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Optional: Clear dataset cache (run this if you get cache errors)\nimport shutil\nimport os\nimport datasets\n\nprint(\"üóëÔ∏è Clearing HuggingFace dataset cache...\")\n\ncache_dir = \"/root/.cache/huggingface/datasets\"\nif os.path.exists(cache_dir):\n    shutil.rmtree(cache_dir)\n    print(\"‚úÖ Cache cleared\")\nelse:\n    print(\"‚ÑπÔ∏è No cache found\")\n\n# Disable caching for fresh download\ndatasets.disable_caching()\nprint(\"‚úÖ Caching disabled - dataset will be downloaded fresh\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "import os\nfrom google.colab import userdata\n\n# IMPORTANT: Verify we're in the correct directory\nrepo_dir = \"/content/my-vits-finetuner-karakalpak\"\n\nif not os.path.exists(repo_dir):\n    print(\"‚ùå ERROR: Repository directory not found!\")\n    print(f\"   Looking for: {repo_dir}\")\n    print(\"\\n‚ö†Ô∏è Please run the repository download cells (Section 3) first!\")\n    raise Exception(\"Repository not downloaded\")\n\n# Change to repository directory\nos.chdir(repo_dir)\nprint(f\"üìÇ Current directory: {os.getcwd()}\")\n\n# Verify the training script exists\ntraining_script = \"run_vits_finetuning.py\"\nif not os.path.exists(training_script):\n    print(f\"‚ùå ERROR: Training script not found!\")\n    print(f\"   Looking for: {training_script}\")\n    print(f\"   In directory: {os.getcwd()}\")\n    print(\"\\nüìã Files in current directory:\")\n    print(os.listdir('.'))\n    raise Exception(\"Training script not found\")\n\nprint(f\"‚úÖ Found training script: {training_script}\")\nprint(f\"‚úÖ Config file: {config_path}\")\n\n# Get HuggingFace token from Colab secrets for private dataset access\ntry:\n    hf_token = userdata.get('HF_TOKEN')\n    os.environ['HF_TOKEN'] = hf_token\n    os.environ['HUGGING_FACE_HUB_TOKEN'] = hf_token\n    print(\"‚úÖ HuggingFace token loaded from secrets\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è Warning: Could not load HF_TOKEN from secrets: {e}\")\n    print(\"   If your dataset is private, this will fail!\")\n\nprint(\"\\nüöÄ Starting training...\\n\")\n\n# Run training using accelerate with token in environment\n!accelerate launch run_vits_finetuning.py {config_path}"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import VitsModel, AutoTokenizer\n",
    "import torch\n",
    "import scipy.io.wavfile\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "model_path = training_config['output_dir']\n",
    "\n",
    "print(f\"üì• Loading model from: {model_path}\")\n",
    "model = VitsModel.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"‚úÖ Model loaded on {device}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with Karakalpak text\n",
    "test_texts = [\n",
    "    \"S√°lem, qalaysƒ±z?\",\n",
    "    \"M√∫g√°lim j√°qsƒ±.\",\n",
    "    \"Men oqƒ±p atƒ±rman.\",\n",
    "]\n",
    "\n",
    "print(\"üé§ Generating speech...\\n\")\n",
    "\n",
    "for i, text in enumerate(test_texts, 1):\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Sample {i}: {text}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    waveform = outputs.waveform[0].cpu().numpy()\n",
    "    \n",
    "    output_file = f\"output_{i}.wav\"\n",
    "    scipy.io.wavfile.write(\n",
    "        output_file,\n",
    "        rate=model.config.sampling_rate,\n",
    "        data=waveform\n",
    "    )\n",
    "    \n",
    "    print(f\"üíæ Saved: {output_file}\")\n",
    "    display(Audio(waveform, rate=model.config.sampling_rate))\n",
    "    print()\n",
    "\n",
    "print(\"‚úÖ All samples generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîü Custom Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your own text here!\n",
    "custom_text = \"S√°lem, bul men!\"\n",
    "\n",
    "print(f\"üìù Generating: {custom_text}\\n\")\n",
    "\n",
    "inputs = tokenizer(custom_text, return_tensors=\"pt\").to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "waveform = outputs.waveform[0].cpu().numpy()\n",
    "output_file = \"custom_output.wav\"\n",
    "scipy.io.wavfile.write(output_file, rate=model.config.sampling_rate, data=waveform)\n",
    "\n",
    "print(f\"‚úÖ Saved: {output_file}\\n\")\n",
    "display(Audio(waveform, rate=model.config.sampling_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£1Ô∏è‚É£ Push to HuggingFace Hub (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "push_to_hub = False  # Set to True to push\n",
    "\n",
    "if push_to_hub:\n",
    "    hub_model_id = training_config['hub_model_id']\n",
    "    \n",
    "    if \"your-username\" not in hub_model_id:\n",
    "        print(f\"üì§ Pushing to: {hub_model_id}\")\n",
    "        model.push_to_hub(hub_model_id)\n",
    "        tokenizer.push_to_hub(hub_model_id)\n",
    "        print(f\"\\n‚úÖ Pushed to: https://huggingface.co/{hub_model_id}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Update hub_model_id first!\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Skipping push (set push_to_hub=True to enable)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£2Ô∏è‚É£ Download Model Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "output_dir = training_config['output_dir']\n",
    "zip_filename = \"mms-tts-kaa-finetuned\"\n",
    "\n",
    "print(f\"üì¶ Creating ZIP archive...\")\n",
    "shutil.make_archive(zip_filename, 'zip', output_dir)\n",
    "\n",
    "print(f\"\\n‚úÖ Archived: {zip_filename}.zip\")\n",
    "print(f\"üì• Download from Files panel on the left\")\n",
    "print(f\"   Size: {os.path.getsize(f'{zip_filename}.zip') / (1024*1024):.2f} MB\")\n",
    "\n",
    "print(f\"\\nüìÇ Model files:\")\n",
    "for file in os.listdir(output_dir):\n",
    "    file_path = os.path.join(output_dir, file)\n",
    "    if os.path.isfile(file_path):\n",
    "        size = os.path.getsize(file_path) / (1024*1024)\n",
    "        print(f\"  - {file}: {size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Congratulations!\n",
    "\n",
    "### You've successfully trained a Karakalpak TTS model!\n",
    "\n",
    "**What you accomplished:**\n",
    "- ‚úÖ Set up the environment\n",
    "- ‚úÖ Downloaded the code (from private repo!)\n",
    "- ‚úÖ Loaded the dataset\n",
    "- ‚úÖ Fine-tuned the model\n",
    "- ‚úÖ Generated speech samples\n",
    "- ‚úÖ Saved the model\n",
    "\n",
    "**Next steps:**\n",
    "1. Experiment with more epochs (200-300)\n",
    "2. Try different hyperparameters\n",
    "3. Add more training data\n",
    "4. Deploy your model\n",
    "5. Share on HuggingFace Hub\n",
    "\n",
    "**Resources:**\n",
    "- [VITS Paper](https://arxiv.org/abs/2106.06103)\n",
    "- [MMS Paper](https://arxiv.org/abs/2305.13516)\n",
    "- [HF VITS Docs](https://huggingface.co/docs/transformers/model_doc/vits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Troubleshooting\n",
    "\n",
    "**1. Out of Memory (OOM):**\n",
    "- Reduce batch size to 2 or 1\n",
    "- Enable gradient_checkpointing\n",
    "- Ensure GPU is enabled\n",
    "\n",
    "**2. Dataset loading fails:**\n",
    "- Fix metadata.csv to include `file_name` column\n",
    "- Or use manual upload method\n",
    "- Check dataset exists on HuggingFace\n",
    "\n",
    "**3. Training is slow:**\n",
    "- Confirm GPU is enabled\n",
    "- Check fp16=True\n",
    "- Verify monotonic_align built correctly\n",
    "\n",
    "**4. Repository download fails:**\n",
    "- Check internet connection\n",
    "- Verify branch name (main vs master)\n",
    "- Check repository exists and is accessible\n",
    "\n",
    "**5. Build errors:**\n",
    "- Ensure Cython is installed\n",
    "- Check numpy is available\n",
    "- Try restarting runtime"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}